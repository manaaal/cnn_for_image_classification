# -*- coding: utf-8 -*-
"""classification101.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15yEJb9nTv8rkIhNWt8d-E3s7BLiYqYuo
"""

from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
#from tensorflow.keras.optimizers import RMSprop
import matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import numpy as np
import cv2
import os

import pathlib

img = pathlib.Path('/content/drive/MyDrive/CNN/img')

cv2.imread("/content/drive/MyDrive/CNN/img/train/car/car20.jpg").shape
#print(cv2.imread("/content/drive/MyDrive/CNN/img/train/car/Copie de car8.jpg"))
img1=cv2.imread("/content/drive/MyDrive/CNN/img/train/car/car20.jpg")

plt.imshow(img1)
#opencv reads in an image as bgr, matplotlib expects it to be rgb

#Convert to bw
img_bw = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)
#img_bw = cv2.imdecode(img1, cv2.IMREAD_GRAYSCALE)
(thresh, img_bw) = cv2.threshold(img_bw, 127, 255, cv2.THRESH_BINARY)
plt.axis('off')
plt.imshow(cv2.cvtColor(img_bw, cv2.COLOR_BGR2RGB))

kernel = np.matrix([[-1,-1,-1],[1,1,1],[0,0,0]])
print(kernel)
img_1 = cv2.filter2D(img_bw, -1, kernel)
plt.axis('off')
plt.imshow(cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB))

kernel = np.matrix([[0,0,0],[1,1,1],[-1,-1,-1]])
print(kernel)
img_1 = cv2.filter2D(img_bw, -1, kernel)
plt.axis('off')
plt.imshow(cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB))

kernel = np.matrix([[-1,1,0],[-1,1,0],[-1,1,0]])
print(kernel)
img_1 = cv2.filter2D(img_bw, -1, kernel)
plt.axis('off')
plt.imshow(cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB))

#pre-process by scaling the image values to between 0 and 1 instead of zero to 255, this helps our deep learning model generalize faster and produces better results
train = ImageDataGenerator(rescale= 1/255)
validation =ImageDataGenerator(rescale= 1/255)

train_dataset = train.flow_from_directory('/content/drive/MyDrive/CNN/img/train',
                                          target_size= (200,200),
                                          batch_size = 3,
                                          class_mode = 'binary')

validation_dataset = validation.flow_from_directory('/content/drive/MyDrive/CNN/img/val',
                                          target_size= (200,200),
                                          batch_size = 3,
                                          class_mode = 'binary')

train_dataset.class_indices
#train_dataset.classes

"""Sequential model= will connect together a list of layers in order"""

model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16,(3,3),activation = 'relu' ,input_shape =(200,200,3)), # give the input dimensions in the first layer [height, width, color channels(RGB)]
                                     tf.keras.layers.MaxPool2D(2,2),
                                      #
                                     tf.keras.layers.Conv2D(32,(3,3),activation = 'relu'),
                                     tf.keras.layers.MaxPool2D(2,2),
                                      
                                     tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),
                                     tf.keras.layers.MaxPool2D(2,2),
                                      ##
                                     tf.keras.layers.Flatten(),
                                     tf.keras.layers.Dense(512,activation= 'relu'),
                                      ##
                                     tf.keras.layers.Dense(1,activation='sigmoid')
                                     ])

model.compile(loss= "binary_crossentropy",
              optimizer ='adam',
              metrics =['binary_accuracy'])

model_fit = model.fit(train_dataset,
                      steps_per_epoch = 3,
                      epochs= 10,
                      validation_data= validation_dataset)

model.summary()

dir_path = '/content/drive/MyDrive/CNN/img/test'
print(os.listdir(dir_path))
for i in os.listdir(dir_path):
     img = image.load_img(dir_path+'/'+ i, target_size=(200,200))
     plt. imshow(img)
     plt.show()
     x=image.img_to_array(img)
     X = np.expand_dims(x,axis =0)
     images = np.vstack([X])
     val = model.predict(images)
     if val == 0:
         print("car")
     else:
         print("tree")

'''# convert the training history to a dataframe
history_df = pd.DataFrame(model_fit.history)
# use Pandas native plot method
history_df['loss'].plot();'''

'''history_df = pd.DataFrame(model_fit.history)
history_df.loc[:, ['loss', 'val_loss']].plot();
print("Minimum validation loss: {}".format(history_df['val_loss'].min()))'''

!pip install lime

from lime import lime_image

explainer = lime_image.LimeImageExplainer()

from tensorflow.keras.preprocessing import image
img = image.load_img('/content/drive/MyDrive/CNN/img/test/tree.jpg', target_size=(200,200))
x=image.img_to_array(img)
X = np.expand_dims(x,axis =0)
images = np.vstack([X])
explanation = explainer.explain_instance(images[0].astype('double'), model.predict,  
                                         top_labels=2, hide_color=0, num_samples=1000)

from skimage.segmentation import mark_boundaries

temp_1, mask_1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)
temp_2, mask_2 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,15))
ax1.imshow(mark_boundaries(temp_1, mask_1))
ax2.imshow(mark_boundaries(temp_2, mask_2))
ax1.axis('off')
ax2.axis('off')

from skimage.segmentation import mark_boundaries

temp_1, mask_1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)
temp_2, mask_2 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,15))
ax1.imshow(mark_boundaries(temp_1, mask_1))
ax2.imshow(mark_boundaries(temp_2, mask_2))
ax1.axis('off')
ax2.axis('off')

#display filters
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image

image_tree = image.load_img('/content/drive/MyDrive/CNN/img/test/tree.jpg', target_size=(200,200))
image_car = image.load_img('/content/drive/MyDrive/CNN/img/test/wcar1.jpg', target_size=(200,200))
def display_image_filtered(name_image,model,layer_name,img):
    inp= model.inputs 
    out1= model.get_layer(layer_name).output  
    feature_map_1= Model(inputs= inp, outputs= out1)  
    #img=cv2.resize(image,(200,200))             
    input_img= np.expand_dims(img, axis=0)      
    f=feature_map_1.predict(input_img) 
    dim = f.shape[3]
    print(f'{layer_name} | Features Shape: {f.shape}')
    print(f'Dimension {dim}')
    fig= plt.figure(figsize=(30,30))
    if not os.path.exists(f'results_{name_image}'):
        os.makedirs(f'results_{name_image}')        
    for i in range(dim):
        ax = fig.add_subplot(dim/2,dim/2,i+1)
        ax.axis('off')
        ax.imshow(f[0,:,:,i])
        plt.imsave(f'results_{name_image}/{name_image}_{layer_name}_{i}.jpg',f[0,:,:,i])



num = 0
for name in ['car','tree']:
    if name == 'tree':
        image = image_tree
    elif name == 'car':
        image = image_car
    plt.axis('off')
    #plt.imshow(image_car)
    #plt.imshow(cv2.cvtColor(image_car, cv2.COLOR_BGR2RGB))
    plt.show()
    for i in range(0,4):
        if num == 0 and i==0:
            print('-----------------------------------------------------')
            print(f'{i+1}st convolutionnal layer')
            display_image_filtered(name,model,f'conv2d',image)
            print('--------')
            print(f'{i-1}nd Pooling')
            display_image_filtered(name,model,f'max_pooling2d',image)
            print('-----------------------------------------------------')
        else:
            print('-----------------------------------------------------')
            print(f'{i+1}st convolutionnal layer')
            display_image_filtered(name,model,f'conv2d_{num+i}',image)
            print('--------')
            print(f'{i+1}nd Pooling')
            display_image_filtered(name,model,f'max_pooling2d_{num+i+1}',image)
            print('-----------------------------------------------------')

"""# Diff"""

batch_size = 3
img_height = 200
img_width = 200

train_data = tf.keras.preprocessing.image_dataset_from_directory(
  img,
  validation_split=0.2,
  subset="training",
  seed=42,
  image_size=(img_height, img_width),
  batch_size=batch_size,
  )

val_data = tf.keras.preprocessing.image_dataset_from_directory(
  img,
  validation_split=0.2,
  subset="validation",
  seed=42,
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_names = val_data.class_names
print(class_names)

model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16,3,activation = 'relu' ,input_shape =(200,200,3)),
                                     tf.keras.layers.MaxPool2D(2,2),
                                      #
                                     tf.keras.layers.BatchNormalization(renorm=True),
                                     tf.keras.layers.Conv2D(32,3,activation = 'relu'),
                                     tf.keras.layers.Conv2D(32,3,activation = 'relu'),
                                     tf.keras.layers.MaxPool2D(2,2),
                                      #
                                     tf.keras.layers.BatchNormalization(renorm=True),
                                     tf.keras.layers.Conv2D(64,3,activation = 'relu'),
                                     tf.keras.layers.Conv2D(64,3,activation = 'relu'),
                                     tf.keras.layers.MaxPool2D(2,2),
                                      #
                                     tf.keras.layers.BatchNormalization(renorm=True),
                                     tf.keras.layers.Conv2D(128,3,activation = 'relu'),
                                     tf.keras.layers.Conv2D(128,3,activation = 'relu'),
                                     tf.keras.layers.MaxPool2D(2,2),
                                      ##
                                     tf.keras.layers.Flatten(), #Flatten layer comes after the base to transform the 2D feature data to 1D data needed by the classifier
                                     tf.keras.layers.Dense(512,activation= 'relu'),
                                     tf.keras.layers.Dense(1,activation= 'sigmoid'),
                                    ])

"""Notice in this definition is how the number of filters doubled block-by-block: 32, 64, 128. This is a common pattern. Since the MaxPool2D layer is reducing the size of the feature maps, we can afford to increase the quantity we create."""

model.compile(loss= "binary_crossentropy",
              optimizer ='adam',
              metrics =['binary_accuracy'])

model_fit = model.fit(train_dataset,
                      steps_per_epoch = 3,
                      epochs= 10,
                      validation_data= validation_dataset)

dir_path = '/content/drive/MyDrive/CNN/img/test'
print(os.listdir(dir_path))
for i in os.listdir(dir_path):
     img = image.load_img(dir_path+'/'+ i, target_size=(200,200))
     plt. imshow(img)
     plt.show()
     x=image.img_to_array(img)
     X = np.expand_dims(x,axis =0)
     images = np.vstack([X])
     val = model.predict(images)
     if val == 0:
         print("car")
     else:
         print("tree")

dir_path = '/content/drive/MyDrive/cnn_images/test'
print(os.listdir(dir_path))
for i in os.listdir(dir_path):
     img = image.load_img(dir_path+'/'+ i, target_size=(200,200))
     plt. imshow(img)
     plt.show()
     x=image.img_to_array(img)
     X = np.expand_dims (x,axis =0)
     images = np.vstack([X])
     val = model.predict(images)
     if val == 0:
         print("tree")
     else:
         print("car")

'''tf.keras.layers.Conv2D(16,3,activation = 'relu' ,input_shape =(200,200,3)),
                                     tf.keras.layers.MaxPool2D(2,2),
                                      #
                                     tf.keras.layers.BatchNormalization(renorm=True),
                                     tf.keras.layers.Conv2D(32,3,activation = 'relu'),
                                     tf.keras.layers.Conv2D(32,3,activation = 'relu'),
                                     tf.keras.layers.MaxPool2D(2,2),
                                      #
                                     tf.keras.layers.Conv2D(64,3,activation = 'relu'),
                                     tf.keras.layers.Conv2D(64,3,activation = 'relu'),
                                     tf.keras.layers.MaxPool2D(2,2),
                                      #
                                     tf.keras.layers.BatchNormalization(renorm=True),
                                     tf.keras.layers.Conv2D(128,3,activation = 'relu'),
                                     tf.keras.layers.Conv2D(128,3,activation = 'relu'),
                                     tf.keras.layers.MaxPool2D(2,2),
                                      ##
                                     tf.keras.layers.Flatten(),
                                      ##
                                     tf.keras.layers.Dense(512,activation= 'relu'),
                                    
                                     tf.keras.layers.Dense(1,activation= 'sigmoid'),'''

'''from tensorflow.keras.layers.experimental import preprocessing
from tensorflow.keras.preprocessing import image_dataset_from_directory'''